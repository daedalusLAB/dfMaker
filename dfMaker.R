######################################################################################################################################
# <dfMaker. The dfMaker function is a comprehensive tool designed for processing and organizing keypoints data generated by OpenPose >
#   Copyright (C) <2024>  <Brian Herreño Jiménez>
#   
#   This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as
# published by the Free Software Foundation, either version 3 of the
# License, or (at your option) any later version.
# 
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Affero General Public License for more details.
# 
# You should have received a copy of the GNU Affero General Public License
# along with this program.  If not, see <https://www.gnu.org/licenses/>.


#############################################################################

dfMaker <- function(input.folder, config.path, output.file = NULL, output.path = NULL, no_save = FALSE, fast_scaling = TRUE, transformation_coords = c(1, 1, 5, 5)) {
  
  # The dfMaker function is a comprehensive tool designed for processing and organizing keypoints data generated by OpenPose.
  # Copyright (C) <2024>  <Brian Herreño Jiménez>
  
  # 'arrow' auto-installation
  if (!require("arrow", quietly = TRUE)) {
    install.packages("arrow", dependencies = TRUE, ask = FALSE)
    library(arrow)
  }
  
  # Load the required library
  library(arrow)
  
  # Initialize variables to store metadata and final data
  all_data <- list()
  default_config <- list(
    extract_datetime = FALSE,
    extract_time = FALSE,
    extract_exp_search = FALSE,
    extract_country_code = FALSE,
    extract_network_code = FALSE,
    extract_program_name = FALSE,
    extract_time_range = FALSE,
    timezone = "America/Los_Angeles"
  )
  
  # Check if config path is provided and read the configuration; use default if not provided
  if (missing(config.path)) {
    config <- default_config
  } else {
    config <- read_json_arrow(config.path, as_data_frame = TRUE) |> as.list()
  }
  
  # List all JSON files in the input directory
  files <- list.files(input.folder, pattern = "*.json", full.names = TRUE)
  
  # Control variable to ensure message is printed only once
  message_printed <- FALSE  
  
  # Loop through each file to process
  for (frame_file in files) {
    
    # Read the JSON file and extract the keypoints data
    rawData <- read_json_arrow(frame_file, as_data_frame = TRUE)[[2]][[1]][2:5]
    
    if (sum(capture.output(rawData) != "<unspecified> [4]") != 0) {
      
      total_points <- sum(sapply(rawData, function(x) length(unlist(x)) / 3))
      # Define the expected number of points for each type of keypoints
      model_type <- ifelse(total_points > 25, "137_points", "25_points")
      rawData <- if (model_type == "25_points") rawData[1] else rawData
      check_points <- if (model_type == "137_points") c(25, 70, 21, 21) else c(25)
      
      if (!message_printed) {  # Check if the message has not been printed yet
        if (model_type == "25_points") {
          print("model b_25")
        } else {
          print("regular model")
        }
        message_printed <- TRUE  # Update the control variable
      }
      
      # Metadata extraction based on the configuration
      metadata <- gsub(".*[\\\\/]", "", frame_file)
      frame <- as.numeric(regmatches(metadata, regexec("[0-9]{12}", metadata)))
      id <- gsub("_\\d{12}_keypoints.json", "", metadata)
      
      # Process keypoints data and compile into data frames
      for (i in 1:nrow(rawData)) {
        
        can_transform <- TRUE  # Initialize transformation flag
        
        if (fast_scaling == FALSE) {
          # Extract the keypoint type and point indices from transformation_coords
          t_typepoint <- transformation_coords[1]         # Keypoint type
          o_point <- transformation_coords[2] + 1         # Index of the origin point
          i_point <- transformation_coords[3] + 1         # Index of the point defining v.i
          j_point <- transformation_coords[4] + 1         # Index of the point defining v.j
          
          # Extract and process the data matrix for the specified keypoint type
          matrix_data_t <- matrix(
            unlist(rawData[i, t_typepoint]), 
            ncol = 3, 
            nrow = check_points[t_typepoint], 
            byrow = TRUE
          )
          matrix_data_t <- apply(matrix_data_t, 2, as.numeric)
          matrix_data_t[, 1:2][matrix_data_t[, 1:2] == 0] <- NA  # Zeros as NAs
          
          # Validate that o_point, i_point, and j_point are within the allowed range
          if (max(o_point, i_point, j_point) > nrow(matrix_data_t)) {
            can_transform <- FALSE
          } else {
            # Set up the vectors `origin`, `v.i`, and `v.j` based on `matrix_data_t`
            origin <- matrix_data_t[o_point, 1:2]  # Extract the origin point
            v.i <- matrix_data_t[i_point, 1:2] - origin  # Vector v.i
            
            # Determine v.j based on whether i_point equals j_point
            if (i_point == j_point) {
              # Compute v.j as the orthogonal vector to v.i
              v.j <- c(v.i[2],- v.i[1])
            } else {
              # Use the provided j_point to compute v.j
              v.j <- matrix_data_t[j_point, 1:2] - origin
            }
            
            # Check if any of the keypoints are NA
            if (any(is.na(origin)) || any(is.na(v.i)) || any(is.na(v.j))) {
              can_transform <- FALSE
            }
          }
        }
        
        for (j in 1:ncol(rawData)) {
          matrix_data <- matrix(unlist(rawData[i, j]), ncol = 3, nrow = check_points[j], byrow = TRUE)
          matrix_data <- apply(matrix_data, 2, as.numeric)
          matrix_data[, 1:2][matrix_data[, 1:2] == 0] <- NA  # Zeros as NAs
          
          # Create the origin vector when j=1 and fast_scaling is TRUE
          if (j == 1 && fast_scaling == TRUE) {
            o_point <- transformation_coords[2] + 1      # Index of the origin point
            i_point <- transformation_coords[3] + 1      # Index of the point defining v.i
            
            origin <- matrix_data[o_point, 1:2]          # Extract origin point
            v.i <- matrix_data[i_point, 1:2] - origin    # Vector v.i
            v.j <- c(-v.i[2], v.i[1])                    # Orthogonal vector to v.i
            
            # Check for NA values
            if (any(is.na(origin)) || any(is.na(v.i))) {
              can_transform <- FALSE
            }
          }
          
          m <- sweep(matrix_data[, 1:2], 2, origin, FUN = "-")  # Subtract origin from all points
          
          if (fast_scaling == FALSE) {
            if (can_transform) {
              # Transformation matrix
              a <- matrix(c(v.i, v.j), nrow = 2)
              
              # Compute determinant
              common_denominator <- det(a)
              
              # Check if determinant is NA or zero
              if (is.na(common_denominator) || common_denominator == 0) {
                newm <- matrix(NA, nrow = nrow(m), ncol = 2)
              } else {
                # Use Cramer's Rule to compute the transformed coordinates
                newm <- matrix(NA, nrow = nrow(m), ncol = 2)
                for (k in 1:nrow(m)) {
                  b <- m[k, ]
                  # Compute numerator for x and y using Cramer's Rule
                  numerator_x <- det(matrix(c(b, v.j), nrow = 2))
                  numerator_y <- det(matrix(c(v.i, b), nrow = 2))
                  newx <- numerator_x / common_denominator
                  newy <- numerator_y / common_denominator
                  newm[k, ] <- c(newx, newy)
                }
              }
            } else {
              # Cannot perform transformation, set newm to NA
              newm <- matrix(NA, nrow = nrow(m), ncol = 2)
            }
          } else {
            # Fast scaling
            if (can_transform) {
              scaling_factor <- v.i[1]
              if (is.na(scaling_factor) || scaling_factor == 0) {
                newm <- matrix(NA, nrow = nrow(m), ncol = 2)
              } else {
                newm <- m / scaling_factor                   # Scale
                newm[, 2] <- -newm[, 2]                      # Invert y-axis
              }
            } else {
              # Cannot perform transformation, set newm to NA
              newm <- matrix(NA, nrow = nrow(m), ncol = 2)
            }
          }
          
          # Combine individual keypoints data into a data frame with metadata
          frame_data_list <- list(
            matrix_data = matrix_data,
            newm = newm,
            type_points = gsub("_2d", "", colnames(rawData[j])),
            people_id = i,
            points = c(0:(nrow(matrix_data) - 1)),
            id = id, 
            frame = frame
          )
          
          # Add the data frame to the list
          df <- data.frame(frame_data_list)
          all_data[[length(all_data) + 1]] <- df
        }
      }
      
      cat("\n")  # File separator
      cat("\nThe frame ", frame, " has been read\n")
      
    } else {
      # If rawData is empty, print a message indicating it
      cat("File:", basename(frame_file), "\n")
      cat("File is empty\n\n")
    }
    
  }
  # Combine all the individual frames into one data frame
  final_data <- do.call(rbind, all_data)
  colnames(final_data)[1:5] <- c("x", "y", "c", "nx", "ny")
  
  if (!no_save) {
    # Use processed_id for auto-naming if output.file is NULL or empty
    if (is.null(output.file) || output.file == "") {
      if (length(unique(final_data$id)) != 1) {
        stop(paste("Error: Multiple unique IDs found:", paste(unique(final_data$id), collapse = ", ")))
      } else {
        if (!is.null(output.path)) {
          # Add last "/"
          if (!grepl("/$", output.path)) {
            output.path <- paste0(output.path, "/")
          }
          dir.create(output.path, recursive = TRUE, showWarnings = FALSE)
          output.file <- paste0(output.path, unique(final_data$id), ".parquet")
        } else {
          dir.create("./df_outputs/", recursive = TRUE, showWarnings = FALSE)
          output.file <- paste0("./df_outputs/", unique(final_data$id), ".parquet")
        }
      }
    }
    
    # Determine the output format based on the file extension
    if (!is.null(output.file)) {
      file_ext <- tools::file_ext(output.file)
      if (file_ext == "csv") {
        write.csv(final_data, output.file, row.names = FALSE)
      } else if (file_ext == "parquet") {
        arrow::write_parquet(final_data, sink = output.file)
      } else {
        warning("Unsupported file extension. Returning data frame.")
      }
    }
  }
  
  return(final_data)
}

# Save new version
save(dfMaker, file = "dfMaker.rda")




